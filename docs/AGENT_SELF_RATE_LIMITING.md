# Agent Self-Rate Limiting: Trust Over Infrastructure

## The Core Idea

Instead of building complex infrastructure to enforce rate limits around agents, give them a `sleep(seconds)` tool and explain the constraints in plain English. Let the agent manage its own timing, just as you would trust a human operator.

## The Problem We're Solving

AWS Bedrock has a 15 RPM (requests per minute) rate limit. Traditional approaches involve:
- Complex orchestration logic with calculated wait times
- Step Functions state machines managing timing between turns
- Infrastructure that treats the agent as something that needs to be "protected from itself"

This creates engineering overhead and treats intelligent agents as if they can't understand or follow simple rules.

## The Solution: A `sleep()` Tool

### Implementation
```javascript
// In tool definitions
{
  name: 'sleep',
  description: 'Pause execution for a specified number of seconds. Use this to self-regulate timing and avoid rate limits.',
  parameters: {
    seconds: {
      type: 'number',
      description: 'Number of seconds to sleep (can be fractional, e.g., 4.5)',
      required: true
    }
  }
}

// In tool handler
async function handleSleep(seconds) {
  await new Promise(resolve => setTimeout(resolve, seconds * 1000));
  return { status: 'slept', duration_seconds: seconds };
}
```

### Prompt Instructions
```
RATE LIMIT AWARENESS:
You are making API calls to AWS Bedrock, which has a rate limit of 15 requests per minute.
To avoid throttling errors, you should pace your actions appropriately.

You have access to a sleep(seconds) tool that pauses execution.
- Use it strategically between actions when needed to stay within rate limits
- Example: If you plan 8 actions in a turn and know the limit is 15/min (4 seconds per action),
  you might sleep(4) between batches of actions
- Think of this like a human operator who understands "don't go too fast"

Remember: Throttling errors waste time and cost money. Self-regulate proactively.
```

## The Philosophy: "Why Am I Doing This?"

### The Heuristic
When building complex infrastructure to work around agent limitations, ask: **"If they're so smart, why am I doing this?"**

If the answer is "because the agent might mess up," reconsider whether you're underestimating the agent's capability.

### The Human Analogy
You don't want a human to speed? You give them:
1. A speed limit (plain English explanation)
2. A penalty if needed (throttling errors cost time/money)

You DON'T build a mechanical governor into their car's engine. That's what we're doing when we over-engineer infrastructure around agents.

## Why This Works

### 1. Agents Already Know This Stuff
Language models have been trained on:
- Rate limiting concepts and strategies
- Timing and pacing algorithms
- Resource management techniques
- API best practices

They don't need to be taught these concepts from scratchâ€”they need to be empowered to apply them.

### 2. Emergent Behavior Is the Goal
This project is about observing **emergent intelligent behavior**, not micromanaging every decision.

As the project author said:
> "I want to be compelled to say 'wow, why didn't I think of that?' (what the agent devised for some spatial solution)"

If we're constantly stepping in to manage rate limits, we never see what the agent would naturally do.

### 3. Solutions for Agents = Solutions for Humans
Time and time again, the solution for an agent is **in principle the same solution that would work for a person**:
- Clear explanation of constraints
- Tools to work within those constraints
- Consequences for violations
- Trust that they'll figure it out

## Practical Benefits

### Simplified Architecture
- **Before**: Step Functions with calculated waits, complex state management
- **After**: Agent decides when to sleep based on its own planning

### Better Adaptation
- Agent can adjust timing based on actual behavior patterns
- Can batch actions more intelligently knowing it has sleep() available
- Can optimize for different goals (speed vs. safety vs. cost)

### Natural Feedback Loop
- Throttling errors teach the agent what doesn't work
- Success teaches what does work
- No different from how humans learn operational constraints

## Example Turn with Self-Regulation

```
THOUGHT: I've identified a promising corridor to the east. I want to explore it
quickly but need to respect the 15 RPM rate limit. At 15/min, I have ~4 seconds
per action safely. I'll batch 4 moves, sleep briefly, then continue.

ACTIONS:
- move_east [1/8]
- move_east [2/8]
- move_east [3/8]
- move_east [4/8]
- sleep(5) [5/8]  // Strategic pause to stay under rate limit
- move_east [6/8]
- move_east [7/8]
- move_north [8/8]  // Check for branches

OBSERVATION: Successfully explored corridor without throttling. The brief pause
kept me well within rate limits while maintaining exploration efficiency.
```

## What Else Are You Over-Engineering?

This heuristic applies beyond rate limiting:

### Questions to Ask
- Are you building retry logic? Or could you explain to the agent what errors mean and let it retry?
- Are you enforcing turn structure? Or could the agent decide how many actions per turn?
- Are you calculating optimal paths? Or could the agent apply its knowledge of Dijkstra's, A*, etc.?
- Are you managing memory? Or could the agent decide when to recall vs. explore?

### The Test
If you're writing code to prevent the agent from making a mistake that a human wouldn't make, you're probably over-engineering.

## Implementation Status

**Current State**: NOT IMPLEMENTED
**Priority**: LOW (rate limiting currently handled via 2 RPM parameter setting with 30s waits)

**Why Document This Now?**
This represents a philosophical breakthrough about the project's design principles. Even if not implemented immediately, it guides future decisions about trusting agent capability vs. building defensive infrastructure.

## Related Concepts

- **Emergent Behavior**: The goal of seeing agents devise solutions we didn't anticipate
- **Von Neumann Neighborhoods**: Trust agents to work within spatial constraints (cardinal-only movement)
- **Prompt Clarity**: Clear instructions over complex enforcement (v3-react-adaptive-clear prompt)
- **"Diagonal Miracles"**: Rejecting shortcuts that bypass physical constraints

## Key Insight

The same person who chats with Claude Haiku for hours about life and technology, getting substantive replies, was initially hesitant to trust it could understand basic rate limiting.

**The realization**: If they can grasp complex philosophical concepts, they can definitely grasp "don't make requests too fast."

---

*"Don't want a human to speed? Give them a speed limit and then a penalty if needed."*
